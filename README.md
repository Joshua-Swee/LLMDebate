
  
<h1 align="center">Debate and Judge Agents with Llama 3</h1>      
This project aims to showcase the capability of the LLama 3 LLM [1] and prompt engineering in becoming useful agents in a debate scenario, being both debaters and judges. 

The two chatbots interfaces are based on Gradio, adapted from a guide by Shrinath Suresh [2].

With the debate agent, we can change the quality of its counterarguments, which can be used as a medium for debate practice.
(A = Simple, B = Moderate, C = Complex)

With the judge agent, we can compare two counterarguments and obtain an explanation of which counterargument is stronger, when it comes to the quality of its structure.

For both agents, the idea of counterargument quality is based on the Toulmin Model of Argumentation [3], and an increase in quality would correspond to an increase in the components found in the Toulmin model.
      
## 1. Hardware Requirements 
  
### Minimum Requirements:  
- CPU: Intel 6th Generation CPU or Equivalent       
- RAM: 8GB DDR4      
- Operating System: Windows 10      
- Storage: 20GB      
  
### Recommended Requirements:  
- CPU: 6-8 Core AMD Ryzen 2nd Generation CPU or better      
- RAM: 16GB DDR4      
- Operating System: Windows 11      
- Storage: 20GB      
   
      
## 2. Prerequisites  
- Python >= 3.10.8       
- Microsoft Visual Studio 2022 >= 17.3.6, which the following individual components:      
  - C++ Cmake tools for Windows      
  - Windows 10/11 SDK      
  - C++ Core features      
  - MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)      

## 3. Obtaining Dependencies 
  
### 3.1 Installing Required Modules
  
From a terminal within the `software` folder:      
1. Install llama-cpp-python
	1. Run`pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose` 
2. Install all required dependencies from the requirements.txt file, using the code:       
`pip install -r requirements.txt`
### 3.2 Downloading the LLM
Due to a large file size, the LLM will have to be separately downloaded.  
1. Click [here](https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf?download=true) to download a quantised version [4] of the Llama-3 8B LLM, which will be used by the debate and judge agents.       
2. Once downloaded, move the `.gguf` file into the `software` folder.      

## 4. Running the Agents
### 4.1 Running Locally
I recommend that these agents are ran separately, avoid slowdowns and save system resources.
#### Debate Agent  
1. Within the `software` folder, run `debate.py`, from your editor, or by running: 
`python debate.py` 
2. Eventually, you will obtain a message:
`Running on local URL:  http://127.0.0.1:7860` Now, you may access the LLM through [http://127.0.0.1:7860](http://127.0.0.1:7860)
#### Judge Agent  
1. Within the `software` folder, run `judge.py`, from your editor, or by running: 
`python judge.py` 
2. Eventually, you will obtain a message:
`Running on local URL:  http://127.0.0.1:7860` Now, you may access the LLM through [http://127.0.0.1:7860](http://127.0.0.1:7860)  
### 4.2 Sharing Online   
  
You can optionally share the agents to be used online through a link generated by Gradio. Just add ` share=True` as an argument in `demo.launch()` at the bottom of the `judge.py` or `debate.py` file and run it the agents as usual.  An additional URL will be generated alongside the local URL. The URL can be accessed online, but all processing still occurs locally on your device.

## 5. References
[1] Introducing Meta Llama 3: The most capable openly available LLM to date (no date) Meta AI. Available at: https://ai.meta.com/blog/meta-llama-3/

[2] Suresh, S. (2023) ‘Implementing Streaming Chatbot with Langchain Callbacks: A Step-by-Step Guide’, Medium, 15 December. Available at: https://medium.com/@shrinath.suresh/implementing-streaming-chatbot-with-langchain-callbacks-a-step-by-step-guide-a527a7d65b8b

[3] Toulmin, S.E. (2003) The Uses of Argument. Cambridge University Press.

[4] QuantFactory/Meta-Llama-3-8B-Instruct-GGUF · Hugging Face (2024). Available at: https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF